{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248291c5",
   "metadata": {},
   "source": [
    "# Convert FFB6D to TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db67a3",
   "metadata": {},
   "source": [
    "Requirements for this to work properlyrepo:\n",
    "\n",
    "- h5py\n",
    "- opencv3\n",
    "- pytorch\n",
    "- torchaudio\n",
    "- cuda-toolkit\n",
    "- torchvision\n",
    "- numpy\n",
    "- pyyaml\n",
    "- pprint\n",
    "- enum34\n",
    "- future\n",
    "- scipy\n",
    "- matplotlib\n",
    "- transforms3d\n",
    "- scikit_image\n",
    "- lmdb\n",
    "- setuptools\n",
    "- cffi\n",
    "- easydict\n",
    "- plyfile\n",
    "- pillow\n",
    "- glumpy\n",
    "- pandas\n",
    "- libjasper-dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417b7a3",
   "metadata": {},
   "source": [
    "Start with some basic configurations for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96682ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RandLA-Net-pytorch'...\n",
      "remote: Enumerating objects: 72, done.\u001b[K\n",
      "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
      "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
      "remote: Total 72 (delta 5), reused 68 (delta 5), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (72/72), 15.02 MiB | 4.89 MiB/s, done.\n",
      "Resolving deltas: 100% (5/5), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth=1 git@github.com:qiqihaer/RandLA-Net-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef599dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: 0: Can't open compile_op.sh\r\n"
     ]
    }
   ],
   "source": [
    "!cd RandLA-Net-pytorch\n",
    "!sh compile_op.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c23846",
   "metadata": {},
   "source": [
    "# Add configuration for RandLAN & PSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407c0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "import colorsys, random, os, sys\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "sys.path.append(BASE_DIR)\n",
    "sys.path.append(os.path.join(BASE_DIR, 'utils'))\n",
    "\n",
    "import cpp_wrappers.cpp_subsampling.grid_subsampling as cpp_subsampling\n",
    "import nearest_neighbors.lib.python.nearest_neighbors as nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf99bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigSemanticKITTI:\n",
    "    k_n = 16  # KNN\n",
    "    num_layers = 4  # Number of layers\n",
    "    num_points = 4096 * 11  # Number of input points\n",
    "    num_classes = 19  # Number of valid classes\n",
    "    sub_grid_size = 0.06  # preprocess_parameter\n",
    "\n",
    "    batch_size = 6  # batch_size during training\n",
    "    val_batch_size = 20  # batch_size during validation and test\n",
    "    train_steps = 500  # Number of steps per epochs\n",
    "    val_steps = 100  # Number of validation steps per epoch\n",
    "\n",
    "    sub_sampling_ratio = [4, 4, 4, 4]  # sampling ratio of random sampling at each layer\n",
    "    d_out = [16, 64, 128, 256]  # feature dimension\n",
    "    num_sub_points = [num_points // 4, num_points // 16, num_points // 64, num_points // 256]\n",
    "\n",
    "    noise_init = 3.5  # noise initial parameter\n",
    "    max_epoch = 100  # maximum epoch during training\n",
    "    learning_rate = 1e-2  # initial learning rate\n",
    "    lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate\n",
    "\n",
    "    train_sum_dir = 'train_log'\n",
    "    saving = True\n",
    "    saving_path = None\n",
    "\n",
    "\n",
    "class ConfigS3DIS:\n",
    "    k_n = 16  # KNN\n",
    "    num_layers = 5  # Number of layers\n",
    "    num_points = 40960  # Number of input points\n",
    "    num_classes = 13  # Number of valid classes\n",
    "    sub_grid_size = 0.04  # preprocess_parameter\n",
    "\n",
    "    batch_size = 6  # batch_size during training\n",
    "    val_batch_size = 20  # batch_size during validation and test\n",
    "    train_steps = 500  # Number of steps per epochs\n",
    "    val_steps = 100  # Number of validation steps per epoch\n",
    "\n",
    "    sub_sampling_ratio = [4, 4, 4, 4, 2]  # sampling ratio of random sampling at each layer\n",
    "    d_out = [16, 64, 128, 256, 512]  # feature dimension\n",
    "\n",
    "    noise_init = 3.5  # noise initial parameter\n",
    "    max_epoch = 100  # maximum epoch during training\n",
    "    learning_rate = 1e-2  # initial learning rate\n",
    "    lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate\n",
    "\n",
    "    train_sum_dir = 'train_log'\n",
    "    saving = True\n",
    "    saving_path = None\n",
    "\n",
    "\n",
    "class ConfigSemantic3D:\n",
    "    k_n = 16  # KNN\n",
    "    num_layers = 5  # Number of layers\n",
    "    num_points = 65536  # Number of input points\n",
    "    num_classes = 8  # Number of valid classes\n",
    "    sub_grid_size = 0.06  # preprocess_parameter\n",
    "\n",
    "    batch_size = 4  # batch_size during training\n",
    "    val_batch_size = 16  # batch_size during validation and test\n",
    "    train_steps = 500  # Number of steps per epochs\n",
    "    val_steps = 100  # Number of validation steps per epoch\n",
    "\n",
    "    sub_sampling_ratio = [4, 4, 4, 4, 2]  # sampling ratio of random sampling at each layer\n",
    "    d_out = [16, 64, 128, 256, 512]  # feature dimension\n",
    "\n",
    "    noise_init = 3.5  # noise initial parameter\n",
    "    max_epoch = 100  # maximum epoch during training\n",
    "    learning_rate = 1e-2  # initial learning rate\n",
    "    lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate\n",
    "\n",
    "    train_sum_dir = 'train_log'\n",
    "    saving = True\n",
    "    saving_path = None\n",
    "\n",
    "    augment_scale_anisotropic = True\n",
    "    augment_symmetries = [True, False, False]\n",
    "    augment_rotation = 'vertical'\n",
    "    augment_scale_min = 0.8\n",
    "    augment_scale_max = 1.2\n",
    "    augment_noise = 0.001\n",
    "    augment_occlusion = 'none'\n",
    "    augment_color = 0.8\n",
    "\n",
    "\n",
    "class DataProcessing:\n",
    "    @staticmethod\n",
    "    def load_pc_semantic3d(filename):\n",
    "        pc_pd = pd.read_csv(filename, header=None, delim_whitespace=True, dtype=np.float16)\n",
    "        pc = pc_pd.values\n",
    "        return pc\n",
    "\n",
    "    @staticmethod\n",
    "    def load_label_semantic3d(filename):\n",
    "        label_pd = pd.read_csv(filename, header=None, delim_whitespace=True, dtype=np.uint8)\n",
    "        cloud_labels = label_pd.values\n",
    "        return cloud_labels\n",
    "\n",
    "    @staticmethod\n",
    "    def load_pc_kitti(pc_path):\n",
    "        scan = np.fromfile(pc_path, dtype=np.float32)\n",
    "        scan = scan.reshape((-1, 4))\n",
    "        points = scan[:, 0:3]  # get xyz\n",
    "        return points\n",
    "\n",
    "    @staticmethod\n",
    "    def load_label_kitti(label_path, remap_lut):\n",
    "        label = np.fromfile(label_path, dtype=np.uint32)\n",
    "        label = label.reshape((-1))\n",
    "        sem_label = label & 0xFFFF  # semantic label in lower half\n",
    "        inst_label = label >> 16  # instance id in upper half\n",
    "        assert ((sem_label + (inst_label << 16) == label).all())\n",
    "        sem_label = remap_lut[sem_label]\n",
    "        return sem_label.astype(np.int32)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_list(dataset_path, test_scan_num):\n",
    "        seq_list = np.sort(os.listdir(dataset_path))\n",
    "\n",
    "        train_file_list = []\n",
    "        test_file_list = []\n",
    "        val_file_list = []\n",
    "        for seq_id in seq_list:\n",
    "            seq_path = join(dataset_path, seq_id)\n",
    "            pc_path = join(seq_path, 'velodyne')\n",
    "            if seq_id == '08':\n",
    "                val_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])\n",
    "                if seq_id == test_scan_num:\n",
    "                    test_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])\n",
    "            elif int(seq_id) >= 11 and seq_id == test_scan_num:\n",
    "                test_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])\n",
    "            elif seq_id in ['00', '01', '02', '03', '04', '05', '06', '07', '09', '10']:\n",
    "                train_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])\n",
    "\n",
    "        train_file_list = np.concatenate(train_file_list, axis=0)\n",
    "        val_file_list = np.concatenate(val_file_list, axis=0)\n",
    "        if test_scan_num != 'None':\n",
    "            test_file_list = np.concatenate(test_file_list, axis=0)\n",
    "        else:\n",
    "            test_file_list = None\n",
    "        return train_file_list, val_file_list, test_file_list\n",
    "\n",
    "    @staticmethod\n",
    "    def knn_search(support_pts, query_pts, k):\n",
    "        \"\"\"\n",
    "        :param support_pts: points you have, B*N1*3\n",
    "        :param query_pts: points you want to know the neighbour index, B*N2*3\n",
    "        :param k: Number of neighbours in knn search\n",
    "        :return: neighbor_idx: neighboring points indexes, B*N2*k\n",
    "        \"\"\"\n",
    "\n",
    "        neighbor_idx = nearest_neighbors.knn_batch(support_pts, query_pts, k, omp=True)\n",
    "        return neighbor_idx.astype(np.int32)\n",
    "\n",
    "    @staticmethod\n",
    "    def data_aug(xyz, color, labels, idx, num_out):\n",
    "        num_in = len(xyz)\n",
    "        dup = np.random.choice(num_in, num_out - num_in)\n",
    "        xyz_dup = xyz[dup, ...]\n",
    "        xyz_aug = np.concatenate([xyz, xyz_dup], 0)\n",
    "        color_dup = color[dup, ...]\n",
    "        color_aug = np.concatenate([color, color_dup], 0)\n",
    "        idx_dup = list(range(num_in)) + list(dup)\n",
    "        idx_aug = idx[idx_dup]\n",
    "        label_aug = labels[idx_dup]\n",
    "        return xyz_aug, color_aug, idx_aug, label_aug\n",
    "\n",
    "    @staticmethod\n",
    "    def shuffle_idx(x):\n",
    "        # random shuffle the index\n",
    "        idx = np.arange(len(x))\n",
    "        np.random.shuffle(idx)\n",
    "        return x[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def shuffle_list(data_list):\n",
    "        indices = np.arange(np.shape(data_list)[0])\n",
    "        np.random.shuffle(indices)\n",
    "        data_list = data_list[indices]\n",
    "        return data_list\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_sub_sampling(points, features=None, labels=None, grid_size=0.1, verbose=0):\n",
    "        \"\"\"\n",
    "        CPP wrapper for a grid sub_sampling (method = barycenter for points and features\n",
    "        :param points: (N, 3) matrix of input points\n",
    "        :param features: optional (N, d) matrix of features (floating number)\n",
    "        :param labels: optional (N,) matrix of integer labels\n",
    "        :param grid_size: parameter defining the size of grid voxels\n",
    "        :param verbose: 1 to display\n",
    "        :return: sub_sampled points, with features and/or labels depending of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if (features is None) and (labels is None):\n",
    "            return cpp_subsampling.compute(points, sampleDl=grid_size, verbose=verbose)\n",
    "        elif labels is None:\n",
    "            return cpp_subsampling.compute(points, features=features, sampleDl=grid_size, verbose=verbose)\n",
    "        elif features is None:\n",
    "            return cpp_subsampling.compute(points, classes=labels, sampleDl=grid_size, verbose=verbose)\n",
    "        else:\n",
    "            return cpp_subsampling.compute(points, features=features, classes=labels, sampleDl=grid_size,\n",
    "                                           verbose=verbose)\n",
    "\n",
    "    @staticmethod\n",
    "    def IoU_from_confusions(confusions):\n",
    "        \"\"\"\n",
    "        Computes IoU from confusion matrices.\n",
    "        :param confusions: ([..., n_c, n_c] np.int32). Can be any dimension, the confusion matrices should be described by\n",
    "        the last axes. n_c = number of classes\n",
    "        :return: ([..., n_c] np.float32) IoU score\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute TP, FP, FN. This assume that the second to last axis counts the truths (like the first axis of a\n",
    "        # confusion matrix), and that the last axis counts the predictions (like the second axis of a confusion matrix)\n",
    "        TP = np.diagonal(confusions, axis1=-2, axis2=-1)\n",
    "        TP_plus_FN = np.sum(confusions, axis=-1)\n",
    "        TP_plus_FP = np.sum(confusions, axis=-2)\n",
    "\n",
    "        # Compute IoU\n",
    "        IoU = TP / (TP_plus_FP + TP_plus_FN - TP + 1e-6)\n",
    "\n",
    "        # Compute mIoU with only the actual classes\n",
    "        mask = TP_plus_FN < 1e-3\n",
    "        counts = np.sum(1 - mask, axis=-1, keepdims=True)\n",
    "        mIoU = np.sum(IoU, axis=-1, keepdims=True) / (counts + 1e-6)\n",
    "\n",
    "        # If class is absent, place mIoU in place of 0 IoU to get the actual mean later\n",
    "        IoU += mask * mIoU\n",
    "        return IoU\n",
    "\n",
    "    @staticmethod\n",
    "    def get_class_weights(dataset_name):\n",
    "        # pre-calculate the number of points in each category\n",
    "        num_per_class = []\n",
    "        if dataset_name is 'S3DIS':\n",
    "            num_per_class = np.array([3370714, 2856755, 4919229, 318158, 375640, 478001, 974733,\n",
    "                                      650464, 791496, 88727, 1284130, 229758, 2272837], dtype=np.int32)\n",
    "        elif dataset_name is 'Semantic3D':\n",
    "            num_per_class = np.array([5181602, 5012952, 6830086, 1311528, 10476365, 946982, 334860, 269353],\n",
    "                                     dtype=np.int32)\n",
    "        elif dataset_name is 'SemanticKITTI':\n",
    "            num_per_class = np.array([55437630, 320797, 541736, 2578735, 3274484, 552662, 184064, 78858,\n",
    "                                      240942562, 17294618, 170599734, 6369672, 230413074, 101130274, 476491114,\n",
    "                                      9833174, 129609852, 4506626, 1168181])\n",
    "        weight = num_per_class / float(sum(num_per_class))\n",
    "        ce_label_weight = 1 / (weight + 0.02)\n",
    "        return np.expand_dims(ce_label_weight, axis=0)\n",
    "\n",
    "\n",
    "class Plot:\n",
    "    @staticmethod\n",
    "    def random_colors(N, bright=True, seed=0):\n",
    "        brightness = 1.0 if bright else 0.7\n",
    "        hsv = [(0.15 + i / float(N), 1, brightness) for i in range(N)]\n",
    "        colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "        random.seed(seed)\n",
    "        random.shuffle(colors)\n",
    "        return colors\n",
    "\n",
    "    @staticmethod\n",
    "    # def draw_pc(pc_xyzrgb):\n",
    "    #     pc = open3d.PointCloud()\n",
    "    #     pc.points = open3d.Vector3dVector(pc_xyzrgb[:, 0:3])\n",
    "    #     if pc_xyzrgb.shape[1] == 3:\n",
    "    #         open3d.draw_geometries([pc])\n",
    "    #         return 0\n",
    "    #     if np.max(pc_xyzrgb[:, 3:6]) > 20:  ## 0-255\n",
    "    #         pc.colors = open3d.Vector3dVector(pc_xyzrgb[:, 3:6] / 255.)\n",
    "    #     else:\n",
    "    #         pc.colors = open3d.Vector3dVector(pc_xyzrgb[:, 3:6])\n",
    "    #     open3d.draw_geometries([pc])\n",
    "    #     return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_pc_sem_ins(pc_xyz, pc_sem_ins, plot_colors=None):\n",
    "        \"\"\"\n",
    "        pc_xyz: 3D coordinates of point clouds\n",
    "        pc_sem_ins: semantic or instance labels\n",
    "        plot_colors: custom color list\n",
    "        \"\"\"\n",
    "        if plot_colors is not None:\n",
    "            ins_colors = plot_colors\n",
    "        else:\n",
    "            ins_colors = Plot.random_colors(len(np.unique(pc_sem_ins)) + 1, seed=2)\n",
    "\n",
    "        ##############################\n",
    "        sem_ins_labels = np.unique(pc_sem_ins)\n",
    "        sem_ins_bbox = []\n",
    "        Y_colors = np.zeros((pc_sem_ins.shape[0], 3))\n",
    "        for id, semins in enumerate(sem_ins_labels):\n",
    "            valid_ind = np.argwhere(pc_sem_ins == semins)[:, 0]\n",
    "            if semins <= -1:\n",
    "                tp = [0, 0, 0]\n",
    "            else:\n",
    "                if plot_colors is not None:\n",
    "                    tp = ins_colors[semins]\n",
    "                else:\n",
    "                    tp = ins_colors[id]\n",
    "\n",
    "            Y_colors[valid_ind] = tp\n",
    "\n",
    "            ### bbox\n",
    "            valid_xyz = pc_xyz[valid_ind]\n",
    "\n",
    "            xmin = np.min(valid_xyz[:, 0]);\n",
    "            xmax = np.max(valid_xyz[:, 0])\n",
    "            ymin = np.min(valid_xyz[:, 1]);\n",
    "            ymax = np.max(valid_xyz[:, 1])\n",
    "            zmin = np.min(valid_xyz[:, 2]);\n",
    "            zmax = np.max(valid_xyz[:, 2])\n",
    "            sem_ins_bbox.append(\n",
    "                [[xmin, ymin, zmin], [xmax, ymax, zmax], [min(tp[0], 1.), min(tp[1], 1.), min(tp[2], 1.)]])\n",
    "\n",
    "        Y_semins = np.concatenate([pc_xyz[:, 0:3], Y_colors], axis=-1)\n",
    "        Plot.draw_pc(Y_semins)\n",
    "        return Y_semins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69381237",
   "metadata": {},
   "source": [
    "## Some pre-defined Torch Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d025d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from __future__ import (\n",
    "    division,\n",
    "    absolute_import,\n",
    "    with_statement,\n",
    "    print_function,\n",
    "    unicode_literals,\n",
    ")\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.function import InplaceFunction\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tqdm\n",
    "from scipy.stats import t as student_t\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMLP(nn.Sequential):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            args: List[int],\n",
    "            *,\n",
    "            bn: bool = False,\n",
    "            activation=nn.ReLU(inplace=True),\n",
    "            preact: bool = False,\n",
    "            first: bool = False,\n",
    "            name: str = \"\",\n",
    "            instance_norm: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        for i in range(len(args) - 1):\n",
    "            self.add_module(\n",
    "                name + 'layer{}'.format(i),\n",
    "                Conv2d(\n",
    "                    args[i],\n",
    "                    args[i + 1],\n",
    "                    bn=(not first or not preact or (i != 0)) and bn,\n",
    "                    activation=activation\n",
    "                    if (not first or not preact or (i != 0)) else None,\n",
    "                    preact=preact,\n",
    "                    instance_norm=instance_norm\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "class _ConvBase(nn.Sequential):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            activation,\n",
    "            bn,\n",
    "            init,\n",
    "            conv=None,\n",
    "            batch_norm=None,\n",
    "            bias=True,\n",
    "            preact=False,\n",
    "            name=\"\",\n",
    "            instance_norm=False,\n",
    "            instance_norm_func=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        bias = bias and (not bn)\n",
    "        conv_unit = conv(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias\n",
    "        )\n",
    "        init(conv_unit.weight)\n",
    "        if bias:\n",
    "            nn.init.constant_(conv_unit.bias, 0)\n",
    "\n",
    "        if bn:\n",
    "            if not preact:\n",
    "                bn_unit = batch_norm(out_size)\n",
    "            else:\n",
    "                bn_unit = batch_norm(in_size)\n",
    "        if instance_norm:\n",
    "            if not preact:\n",
    "                in_unit = instance_norm_func(out_size, affine=False, track_running_stats=False)\n",
    "            else:\n",
    "                in_unit = instance_norm_func(in_size, affine=False, track_running_stats=False)\n",
    "\n",
    "        if preact:\n",
    "            if bn:\n",
    "                self.add_module(name + 'bn', bn_unit)\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + 'activation', activation)\n",
    "\n",
    "            if not bn and instance_norm:\n",
    "                self.add_module(name + 'in', in_unit)\n",
    "\n",
    "        self.add_module(name + 'conv', conv_unit)\n",
    "\n",
    "        if not preact:\n",
    "            if bn:\n",
    "                self.add_module(name + 'bn', bn_unit)\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + 'activation', activation)\n",
    "\n",
    "            if not bn and instance_norm:\n",
    "                self.add_module(name + 'in', in_unit)\n",
    "\n",
    "\n",
    "class _BNBase(nn.Sequential):\n",
    "\n",
    "    def __init__(self, in_size, batch_norm=None, name=\"\"):\n",
    "        super().__init__()\n",
    "        self.add_module(name + \"bn\", batch_norm(in_size, eps=1e-6, momentum=0.99))\n",
    "\n",
    "        nn.init.constant_(self[0].weight, 1.0)\n",
    "        nn.init.constant_(self[0].bias, 0)\n",
    "\n",
    "\n",
    "class BatchNorm1d(_BNBase):\n",
    "\n",
    "    def __init__(self, in_size: int, *, name: str = \"\"):\n",
    "        super().__init__(in_size, batch_norm=nn.BatchNorm1d, name=name)\n",
    "\n",
    "\n",
    "class BatchNorm2d(_BNBase):\n",
    "\n",
    "    def __init__(self, in_size: int, name: str = \"\"):\n",
    "        super().__init__(in_size, batch_norm=nn.BatchNorm2d, name=name)\n",
    "\n",
    "\n",
    "class Conv1d(_ConvBase):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_size: int,\n",
    "            out_size: int,\n",
    "            *,\n",
    "            kernel_size: int = 1,\n",
    "            stride: int = 1,\n",
    "            padding: int = 0,\n",
    "            activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            bn: bool = False,\n",
    "            init=nn.init.kaiming_normal_,\n",
    "            bias: bool = True,\n",
    "            preact: bool = False,\n",
    "            name: str = \"\",\n",
    "            instance_norm=False\n",
    "    ):\n",
    "        super().__init__(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            activation,\n",
    "            bn,\n",
    "            init,\n",
    "            conv=nn.Conv1d,\n",
    "            batch_norm=BatchNorm1d,\n",
    "            bias=bias,\n",
    "            preact=preact,\n",
    "            name=name,\n",
    "            instance_norm=instance_norm,\n",
    "            instance_norm_func=nn.InstanceNorm1d\n",
    "        )\n",
    "\n",
    "\n",
    "class Conv2d(_ConvBase):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_size: int,\n",
    "            out_size: int,\n",
    "            *,\n",
    "            kernel_size: Tuple[int, int] = (1, 1),\n",
    "            stride: Tuple[int, int] = (1, 1),\n",
    "            padding: Tuple[int, int] = (0, 0),\n",
    "            activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            bn: bool = False,\n",
    "            init=nn.init.kaiming_normal_,\n",
    "            bias: bool = True,\n",
    "            preact: bool = False,\n",
    "            name: str = \"\",\n",
    "            instance_norm=False\n",
    "    ):\n",
    "        super().__init__(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            activation,\n",
    "            bn,\n",
    "            init,\n",
    "            conv=nn.Conv2d,\n",
    "            batch_norm=BatchNorm2d,\n",
    "            bias=bias,\n",
    "            preact=preact,\n",
    "            name=name,\n",
    "            instance_norm=instance_norm,\n",
    "            instance_norm_func=nn.InstanceNorm2d\n",
    "        )\n",
    "\n",
    "\n",
    "class FC(nn.Sequential):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_size: int,\n",
    "            out_size: int,\n",
    "            *,\n",
    "            activation=nn.ReLU(inplace=True),\n",
    "            bn: bool = False,\n",
    "            init=None,\n",
    "            preact: bool = False,\n",
    "            name: str = \"\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        fc = nn.Linear(in_size, out_size, bias=not bn)\n",
    "        if init is not None:\n",
    "            init(fc.weight)\n",
    "        if not bn:\n",
    "            nn.init.constant(fc.bias, 0)\n",
    "\n",
    "        if preact:\n",
    "            if bn:\n",
    "                self.add_module(name + 'bn', BatchNorm1d(in_size))\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + 'activation', activation)\n",
    "\n",
    "        self.add_module(name + 'fc', fc)\n",
    "\n",
    "        if not preact:\n",
    "            if bn:\n",
    "                self.add_module(name + 'bn', BatchNorm1d(out_size))\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + 'activation', activation)\n",
    "\n",
    "\n",
    "def set_bn_momentum_default(bn_momentum):\n",
    "\n",
    "    def fn(m):\n",
    "        if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "            m.momentum = bn_momentum\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "class BNMomentumScheduler(object):\n",
    "\n",
    "    def __init__(\n",
    "            self, model, bn_lambda, last_epoch=-1,\n",
    "            setter=set_bn_momentum_default\n",
    "    ):\n",
    "        if not isinstance(model, nn.Module):\n",
    "            raise RuntimeError(\n",
    "                \"Class '{}' is not a PyTorch nn Module\".format(\n",
    "                    type(model).__name__\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.model = model\n",
    "        self.setter = setter\n",
    "        self.lmbd = bn_lambda\n",
    "\n",
    "        self.step(last_epoch + 1)\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "\n",
    "        self.last_epoch = epoch\n",
    "        self.model.apply(self.setter(self.lmbd(epoch)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMLP(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "        bn=False,\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        preact=False,\n",
    "        first=False,\n",
    "        name=\"\",\n",
    "    ):\n",
    "        # type: (SharedMLP, List[int], bool, Any, bool, bool, AnyStr) -> None\n",
    "        super(SharedMLP, self).__init__()\n",
    "\n",
    "        for i in range(len(args) - 1):\n",
    "            self.add_module(\n",
    "                name + \"layer{}\".format(i),\n",
    "                Conv2d(\n",
    "                    args[i],\n",
    "                    args[i + 1],\n",
    "                    bn=(not first or not preact or (i != 0)) and bn,\n",
    "                    activation=activation\n",
    "                    if (not first or not preact or (i != 0))\n",
    "                    else None,\n",
    "                    preact=preact,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "\n",
    "class _BNBase(nn.Sequential):\n",
    "    def __init__(self, in_size, batch_norm=None, name=\"\"):\n",
    "        super(_BNBase, self).__init__()\n",
    "        self.add_module(name + \"bn\", batch_norm(in_size))\n",
    "\n",
    "        nn.init.constant_(self[0].weight, 1.0)\n",
    "        nn.init.constant_(self[0].bias, 0)\n",
    "\n",
    "\n",
    "class BatchNorm1d(_BNBase):\n",
    "    def __init__(self, in_size, name=\"\"):\n",
    "        # type: (BatchNorm1d, int, AnyStr) -> None\n",
    "        super(BatchNorm1d, self).__init__(in_size, batch_norm=nn.BatchNorm1d, name=name)\n",
    "\n",
    "\n",
    "class BatchNorm2d(_BNBase):\n",
    "    def __init__(self, in_size, name=\"\"):\n",
    "        # type: (BatchNorm2d, int, AnyStr) -> None\n",
    "        super(BatchNorm2d, self).__init__(in_size, batch_norm=nn.BatchNorm2d, name=name)\n",
    "\n",
    "\n",
    "class BatchNorm3d(_BNBase):\n",
    "    def __init__(self, in_size, name=\"\"):\n",
    "        # type: (BatchNorm3d, int, AnyStr) -> None\n",
    "        super(BatchNorm3d, self).__init__(in_size, batch_norm=nn.BatchNorm3d, name=name)\n",
    "\n",
    "\n",
    "class _ConvBase(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size,\n",
    "        out_size,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        dilation,\n",
    "        activation,\n",
    "        bn,\n",
    "        init,\n",
    "        conv=None,\n",
    "        norm_layer=None,\n",
    "        bias=True,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "    ):\n",
    "        super(_ConvBase, self).__init__()\n",
    "\n",
    "        bias = bias and (not bn)\n",
    "        conv_unit = conv(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            bias=bias,\n",
    "        )\n",
    "        init(conv_unit.weight)\n",
    "        if bias:\n",
    "            nn.init.constant_(conv_unit.bias, 0)\n",
    "\n",
    "        if bn:\n",
    "            if not preact:\n",
    "                bn_unit = norm_layer(out_size)\n",
    "            else:\n",
    "                bn_unit = norm_layer(in_size)\n",
    "\n",
    "        if preact:\n",
    "            if bn:\n",
    "                self.add_module(name + \"normlayer\", bn_unit)\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + \"activation\", activation)\n",
    "\n",
    "        self.add_module(name + \"conv\", conv_unit)\n",
    "\n",
    "        if not preact:\n",
    "            if bn:\n",
    "                self.add_module(name + \"normlayer\", bn_unit)\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + \"activation\", activation)\n",
    "\n",
    "\n",
    "class Conv1d(_ConvBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size,\n",
    "        out_size,\n",
    "        kernel_size=1,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=nn.init.kaiming_normal_,\n",
    "        bias=True,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "        norm_layer=BatchNorm1d,\n",
    "    ):\n",
    "        # type: (Conv1d, int, int, int, int, int, int, Any, bool, Any, bool, bool, AnyStr, _BNBase) -> None\n",
    "        super(Conv1d, self).__init__(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            activation,\n",
    "            bn,\n",
    "            init,\n",
    "            conv=nn.Conv1d,\n",
    "            norm_layer=norm_layer,\n",
    "            bias=bias,\n",
    "            preact=preact,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "\n",
    "class Conv2d(_ConvBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size,\n",
    "        out_size,\n",
    "        kernel_size=(1, 1),\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0),\n",
    "        dilation=(1, 1),\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=nn.init.kaiming_normal_,\n",
    "        bias=True,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "        norm_layer=BatchNorm2d,\n",
    "    ):\n",
    "        # type: (Conv2d, int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], Any, bool, Any, bool, bool, AnyStr, _BNBase) -> None\n",
    "        super(Conv2d, self).__init__(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            activation,\n",
    "            bn,\n",
    "            init,\n",
    "            conv=nn.Conv2d,\n",
    "            norm_layer=norm_layer,\n",
    "            bias=bias,\n",
    "            preact=preact,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "\n",
    "class Conv3d(_ConvBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size,\n",
    "        out_size,\n",
    "        kernel_size=(1, 1, 1),\n",
    "        stride=(1, 1, 1),\n",
    "        padding=(0, 0, 0),\n",
    "        dilation=(1, 1, 1),\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=nn.init.kaiming_normal_,\n",
    "        bias=True,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "        norm_layer=BatchNorm3d,\n",
    "    ):\n",
    "        # type: (Conv3d, int, int, Tuple[int, int, int], Tuple[int, int, int], Tuple[int, int, int], Tuple[int, int, int], Any, bool, Any, bool, bool, AnyStr, _BNBase) -> None\n",
    "        super(Conv3d, self).__init__(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            activation,\n",
    "            bn,\n",
    "            init,\n",
    "            conv=nn.Conv3d,\n",
    "            norm_layer=norm_layer,\n",
    "            bias=bias,\n",
    "            preact=preact,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "\n",
    "class FC(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size,\n",
    "        out_size,\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=None,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "    ):\n",
    "        # type: (FC, int, int, Any, bool, Any, bool, AnyStr) -> None\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        fc = nn.Linear(in_size, out_size, bias=not bn)\n",
    "        if init is not None:\n",
    "            init(fc.weight)\n",
    "        if not bn:\n",
    "            nn.init.constant_(fc.bias, 0)\n",
    "\n",
    "        if preact:\n",
    "            if bn:\n",
    "                self.add_module(name + \"bn\", BatchNorm1d(in_size))\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + \"activation\", activation)\n",
    "\n",
    "        self.add_module(name + \"fc\", fc)\n",
    "\n",
    "        if not preact:\n",
    "            if bn:\n",
    "                self.add_module(name + \"bn\", BatchNorm1d(out_size))\n",
    "\n",
    "            if activation is not None:\n",
    "                self.add_module(name + \"activation\", activation)\n",
    "\n",
    "\n",
    "class Seq(nn.Sequential):\n",
    "    def __init__(self, input_channels):\n",
    "        super(Seq, self).__init__()\n",
    "        self.count = 0\n",
    "        self.current_channels = input_channels\n",
    "\n",
    "    def conv1d(\n",
    "        self,\n",
    "        out_size,\n",
    "        kernel_size=1,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=nn.init.kaiming_normal_,\n",
    "        bias=True,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "        norm_layer=BatchNorm1d,\n",
    "    ):\n",
    "        # type: (Seq, int, int, int, int, int, Any, bool, Any, bool, bool, AnyStr) -> Seq\n",
    "\n",
    "        self.add_module(\n",
    "            str(self.count),\n",
    "            Conv1d(\n",
    "                self.current_channels,\n",
    "                out_size,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "                activation=activation,\n",
    "                bn=bn,\n",
    "                init=init,\n",
    "                bias=bias,\n",
    "                preact=preact,\n",
    "                name=name,\n",
    "                norm_layer=norm_layer,\n",
    "            ),\n",
    "        )\n",
    "        self.count += 1\n",
    "        self.current_channels = out_size\n",
    "\n",
    "        return self\n",
    "\n",
    "    def conv2d(\n",
    "        self,\n",
    "        out_size,\n",
    "        kernel_size=(1, 1),\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0),\n",
    "        dilation=(1, 1),\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=nn.init.kaiming_normal_,\n",
    "        bias=True,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "        norm_layer=BatchNorm2d,\n",
    "    ):\n",
    "        # type: (Seq, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], Any, bool, Any, bool, bool, AnyStr) -> Seq\n",
    "\n",
    "        self.add_module(\n",
    "            str(self.count),\n",
    "            Conv2d(\n",
    "                self.current_channels,\n",
    "                out_size,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "                activation=activation,\n",
    "                bn=bn,\n",
    "                init=init,\n",
    "                bias=bias,\n",
    "                preact=preact,\n",
    "                name=name,\n",
    "                norm_layer=norm_layer,\n",
    "            ),\n",
    "        )\n",
    "        self.count += 1\n",
    "        self.current_channels = out_size\n",
    "\n",
    "        return self\n",
    "\n",
    "    def conv3d(\n",
    "        self,\n",
    "        out_size,\n",
    "        kernel_size=(1, 1, 1),\n",
    "        stride=(1, 1, 1),\n",
    "        padding=(0, 0, 0),\n",
    "        dilation=(1, 1, 1),\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=nn.init.kaiming_normal_,\n",
    "        bias=True,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "        norm_layer=BatchNorm3d,\n",
    "    ):\n",
    "        # type: (Seq, int, Tuple[int, int], Tuple[int, int, int], Tuple[int, int, int], Tuple[int, int, int], Any, bool, Any, bool, bool, AnyStr) -> Seq\n",
    "\n",
    "        self.add_module(\n",
    "            str(self.count),\n",
    "            Conv3d(\n",
    "                self.current_channels,\n",
    "                out_size,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "                activation=activation,\n",
    "                bn=bn,\n",
    "                init=init,\n",
    "                bias=bias,\n",
    "                preact=preact,\n",
    "                name=name,\n",
    "                norm_layer=norm_layer,\n",
    "            ),\n",
    "        )\n",
    "        self.count += 1\n",
    "        self.current_channels = out_size\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fc(\n",
    "        self,\n",
    "        out_size,\n",
    "        activation=nn.ReLU(inplace=True),\n",
    "        bn=False,\n",
    "        init=None,\n",
    "        preact=False,\n",
    "        name=\"\",\n",
    "    ):\n",
    "        # type: (Seq, int, Any, bool, Any, bool, AnyStr) -> None\n",
    "\n",
    "        self.add_module(\n",
    "            str(self.count),\n",
    "            FC(\n",
    "                self.current_channels,\n",
    "                out_size,\n",
    "                activation=activation,\n",
    "                bn=bn,\n",
    "                init=init,\n",
    "                preact=preact,\n",
    "                name=name,\n",
    "            ),\n",
    "        )\n",
    "        self.count += 1\n",
    "        self.current_channels = out_size\n",
    "\n",
    "        return self\n",
    "\n",
    "    def dropout(self, p=0.5):\n",
    "        # type: (Seq, float) -> Seq\n",
    "\n",
    "        self.add_module(str(self.count), nn.Dropout(p=0.5))\n",
    "        self.count += 1\n",
    "\n",
    "        return self\n",
    "\n",
    "    def maxpool2d(\n",
    "        self,\n",
    "        kernel_size,\n",
    "        stride=None,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        return_indices=False,\n",
    "        ceil_mode=False,\n",
    "    ):\n",
    "        self.add_module(\n",
    "            str(self.count),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "                return_indices=return_indices,\n",
    "                ceil_mode=ceil_mode,\n",
    "            ),\n",
    "        )\n",
    "        self.count += 1\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "def group_model_params(model, **kwargs):\n",
    "    # type: (nn.Module, ...) -> List[Dict]\n",
    "    decay_group = []\n",
    "    no_decay_group = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.find(\"normlayer\") != -1 or name.find(\"bias\") != -1:\n",
    "            no_decay_group.append(param)\n",
    "        else:\n",
    "            decay_group.append(param)\n",
    "\n",
    "    assert len(list(model.parameters())) == len(decay_group) + len(no_decay_group)\n",
    "\n",
    "    return [\n",
    "        dict(params=decay_group, **kwargs),\n",
    "        dict(params=no_decay_group, weight_decay=0.0, **kwargs),\n",
    "    ]\n",
    "\n",
    "\n",
    "def set_bn_momentum_default(bn_momentum):\n",
    "    def fn(m):\n",
    "        if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "            m.momentum = bn_momentum\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "class BNMomentumScheduler(object):\n",
    "    def __init__(self, model, bn_lambda, last_epoch=-1, setter=set_bn_momentum_default):\n",
    "        if not isinstance(model, nn.Module):\n",
    "            raise RuntimeError(\n",
    "                \"Class '{}' is not a PyTorch nn Module\".format(type(model).__name__)\n",
    "            )\n",
    "\n",
    "        self.model = model\n",
    "        self.setter = setter\n",
    "        self.lmbd = bn_lambda\n",
    "\n",
    "        self.step(last_epoch + 1)\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "\n",
    "        self.last_epoch = epoch\n",
    "        self.model.apply(self.setter(self.lmbd(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d8846",
   "metadata": {},
   "source": [
    "## Add PSPNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7929ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.jit import script, trace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5f099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPModule(nn.Module):\n",
    "    def __init__(self, features, out_features=1024, sizes=(1, 2, 3, 6)):\n",
    "        super(PSPModule, self).__init__()\n",
    "        self.stages = []\n",
    "        self.stages = nn.ModuleList(\n",
    "            [self._make_stage(features, size) for size in sizes]\n",
    "        )\n",
    "        self.bottleneck = nn.Conv2d(\n",
    "            features * (len(sizes) + 1), out_features, kernel_size=1\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _make_stage(self, features, size):\n",
    "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
    "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
    "        return nn.Sequential(prior, conv)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        h, w = feats.size(2), feats.size(3)\n",
    "        priors = [\n",
    "            F.upsample(input=stage(feats), size=(h, w), mode='bilinear')\n",
    "            for stage in self.stages\n",
    "        ] + [feats]\n",
    "        bottle = self.bottleneck(torch.cat(priors, 1))\n",
    "        return self.relu(bottle)\n",
    "\n",
    "\n",
    "class PSPUpsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PSPUpsample, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Modified_PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes=22, sizes=(1, 2, 3, 6), psp_size=2048,\n",
    "                 deep_features_size=1024, backend='resnet18', pretrained=True\n",
    "                 ):\n",
    "        super(Modified_PSPNet, self).__init__()\n",
    "        self.feats = getattr(extractors, backend)(pretrained)\n",
    "        self.psp = PSPModule(psp_size, 1024, sizes)\n",
    "        self.drop_1 = nn.Dropout2d(p=0.3)\n",
    "\n",
    "        self.up_1 = PSPUpsample(1024, 256)\n",
    "        self.up_2 = PSPUpsample(256, 64)\n",
    "        self.up_3 = PSPUpsample(64, 64)\n",
    "\n",
    "        self.drop_2 = nn.Dropout2d(p=0.15)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "        )\n",
    "\n",
    "        self.final_seg = nn.Sequential(\n",
    "            nn.Conv2d(64, n_classes, kernel_size=1),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(deep_features_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f, class_f = self.feats(x)\n",
    "        p = self.psp(f)\n",
    "        p = self.drop_1(p)\n",
    "\n",
    "        p = self.up_1(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_2(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_3(p)\n",
    "\n",
    "        return self.final(p), self.final_seg(p).permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "\n",
    "class PSPNet(nn.Module):\n",
    "    def __init__(\n",
    "            self, n_classes=22, sizes=(1, 2, 3, 6), psp_size=2048,\n",
    "            deep_features_size=1024, backend='resnet18', pretrained=True\n",
    "    ):\n",
    "        super(PSPNet, self).__init__()\n",
    "        self.feats = getattr(extractors, backend)(pretrained)\n",
    "        self.psp = PSPModule(psp_size, 1024, sizes)\n",
    "        self.drop_1 = nn.Dropout2d(p=0.3)\n",
    "\n",
    "        self.up_1 = PSPUpsample(1024, 256)\n",
    "        self.up_2 = PSPUpsample(256, 64)\n",
    "        self.up_3 = PSPUpsample(64, 64)\n",
    "\n",
    "        self.drop_2 = nn.Dropout2d(p=0.15)\n",
    "        self.final = nn.Sequential(\n",
    "            # nn.Conv2d(64, 32, kernel_size=1),\n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "        self.final_seg = nn.Sequential(\n",
    "            nn.Conv2d(64, n_classes, kernel_size=1),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(deep_features_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f, class_f = self.feats(x)\n",
    "        p = self.psp(f)\n",
    "        p = self.drop_1(p)\n",
    "\n",
    "        p = self.up_1(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_2(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_3(p)\n",
    "\n",
    "        return self.final(p), self.final_seg(p).permute(0, 2, 3, 1).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da0631",
   "metadata": {},
   "source": [
    "## Add RandLANet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55618736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.fc0 = pt_utils.Conv1d(config.in_c, 8, kernel_size=1, bn=True)\n",
    "\n",
    "        self.dilated_res_blocks = nn.ModuleList()\n",
    "        d_in = 8\n",
    "        for i in range(self.config.num_layers):\n",
    "            d_out = self.config.d_out[i]\n",
    "            self.dilated_res_blocks.append(Dilated_res_block(d_in, d_out))\n",
    "            d_in = 2 * d_out\n",
    "\n",
    "        d_out = d_in\n",
    "        self.decoder_0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        for j in range(self.config.num_layers):\n",
    "            if j < 3:\n",
    "                d_in = d_out + 2 * self.config.d_out[-j-2]\n",
    "                d_out = 2 * self.config.d_out[-j-2]\n",
    "            else:\n",
    "                d_in = 4 * self.config.d_out[-4]\n",
    "                d_out = 2 * self.config.d_out[-4]\n",
    "            self.decoder_blocks.append(pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True))\n",
    "\n",
    "        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1,1), bn=True)\n",
    "        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1,1), bn=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = pt_utils.Conv2d(32, self.config.num_classes, kernel_size=(1,1), bn=False, activation=None)\n",
    "\n",
    "    def forward(self, end_points):\n",
    "\n",
    "        features = end_points['features']  # Batch*channel*npoints\n",
    "        features = self.fc0(features)\n",
    "\n",
    "        features = features.unsqueeze(dim=3)  # Batch*channel*npoints*1\n",
    "\n",
    "        # ###########################Encoder############################\n",
    "        f_encoder_list = []\n",
    "        for i in range(self.config.num_layers):\n",
    "            f_encoder_i = self.dilated_res_blocks[i](\n",
    "                features, end_points['xyz'][i], end_points['neigh_idx'][i]\n",
    "            )\n",
    "\n",
    "            f_sampled_i = self.random_sample(f_encoder_i, end_points['sub_idx'][i])\n",
    "            features = f_sampled_i\n",
    "            print(\"encoder%d:\"%i, features.size())\n",
    "            if i == 0:\n",
    "                f_encoder_list.append(f_encoder_i)\n",
    "            f_encoder_list.append(f_sampled_i)\n",
    "        # ###########################Encoder############################\n",
    "\n",
    "        features = self.decoder_0(f_encoder_list[-1])\n",
    "\n",
    "        # ###########################Decoder############################\n",
    "        f_decoder_list = []\n",
    "        for j in range(self.config.num_layers):\n",
    "            f_interp_i = self.nearest_interpolation(features, end_points['interp_idx'][-j - 1])\n",
    "            f_decoder_i = self.decoder_blocks[j](torch.cat([f_encoder_list[-j - 2], f_interp_i], dim=1))\n",
    "\n",
    "            features = f_decoder_i\n",
    "            print(\"decoder%d:\"%j, features.size())\n",
    "            f_decoder_list.append(f_decoder_i)\n",
    "        # ###########################Decoder############################\n",
    "\n",
    "        features = self.fc1(features)\n",
    "        features = self.fc2(features)\n",
    "        features = self.dropout(features)\n",
    "        features = self.fc3(features)\n",
    "        f_out = features.squeeze(3)\n",
    "\n",
    "        end_points['logits'] = f_out\n",
    "        return end_points\n",
    "\n",
    "    @staticmethod\n",
    "    def random_sample(feature, pool_idx):\n",
    "        \"\"\"\n",
    "        :param feature: [B, N, d] input features matrix\n",
    "        :param pool_idx: [B, N', max_num] N' < N, N' is the selected position after pooling\n",
    "        :return: pool_features = [B, N', d] pooled features matrix\n",
    "        \"\"\"\n",
    "        feature = feature.squeeze(dim=3)  # batch*channel*npoints\n",
    "        num_neigh = pool_idx.shape[-1]\n",
    "        d = feature.shape[1]\n",
    "        batch_size = pool_idx.shape[0]\n",
    "        pool_idx = pool_idx.reshape(batch_size, -1)  # batch*(npoints,nsamples)\n",
    "        pool_features = torch.gather(feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1))\n",
    "        pool_features = pool_features.reshape(batch_size, d, -1, num_neigh)\n",
    "        pool_features = pool_features.max(dim=3, keepdim=True)[0]  # batch*channel*npoints*1\n",
    "        return pool_features\n",
    "\n",
    "    @staticmethod\n",
    "    def nearest_interpolation(feature, interp_idx):\n",
    "        \"\"\"\n",
    "        :param feature: [B, C, npoints] input features matrix\n",
    "        :param interp_idx: [B, up_num_points, 1] nearest neighbour index\n",
    "        :return: [B, c, up_num_points, 1] interpolated features matrix\n",
    "        \"\"\"\n",
    "        feature = feature.squeeze(dim=3)  # batch*channel*npoints\n",
    "        batch_size = interp_idx.shape[0]\n",
    "        up_num_points = interp_idx.shape[1]\n",
    "        interp_idx = interp_idx.reshape(batch_size, up_num_points)\n",
    "        interpolated_features = torch.gather(feature, 2, interp_idx.unsqueeze(1).repeat(1,feature.shape[1],1))\n",
    "        interpolated_features = interpolated_features.unsqueeze(3)  # batch*channel*npoints*1\n",
    "        return interpolated_features\n",
    "\n",
    "\n",
    "\n",
    "def compute_acc(end_points):\n",
    "\n",
    "    logits = end_points['valid_logits']\n",
    "    labels = end_points['valid_labels']\n",
    "    logits = logits.max(dim=1)[1]\n",
    "    acc = (logits == labels).sum().float() / float(labels.shape[0])\n",
    "    end_points['acc'] = acc\n",
    "    return acc, end_points\n",
    "\n",
    "\n",
    "class IoUCalculator:\n",
    "    def __init__(self, cfg):\n",
    "        self.gt_classes = [0 for _ in range(cfg.num_classes)]\n",
    "        self.positive_classes = [0 for _ in range(cfg.num_classes)]\n",
    "        self.true_positive_classes = [0 for _ in range(cfg.num_classes)]\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def add_data(self, end_points):\n",
    "        logits = end_points['valid_logits']\n",
    "        labels = end_points['valid_labels']\n",
    "        pred = logits.max(dim=1)[1]\n",
    "        pred_valid = pred.detach().cpu().numpy()\n",
    "        labels_valid = labels.detach().cpu().numpy()\n",
    "\n",
    "        val_total_correct = 0\n",
    "        val_total_seen = 0\n",
    "\n",
    "        correct = np.sum(pred_valid == labels_valid)\n",
    "        val_total_correct += correct\n",
    "        val_total_seen += len(labels_valid)\n",
    "\n",
    "        conf_matrix = confusion_matrix(labels_valid, pred_valid, np.arange(0, self.cfg.num_classes, 1))\n",
    "        self.gt_classes += np.sum(conf_matrix, axis=1)\n",
    "        self.positive_classes += np.sum(conf_matrix, axis=0)\n",
    "        self.true_positive_classes += np.diagonal(conf_matrix)\n",
    "\n",
    "    def compute_iou(self):\n",
    "        iou_list = []\n",
    "        for n in range(0, self.cfg.num_classes, 1):\n",
    "            if float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n]) != 0:\n",
    "                iou = self.true_positive_classes[n] / float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n])\n",
    "                iou_list.append(iou)\n",
    "            else:\n",
    "                iou_list.append(0.0)\n",
    "        mean_iou = sum(iou_list) / float(self.cfg.num_classes)\n",
    "        return mean_iou, iou_list\n",
    "\n",
    "\n",
    "\n",
    "class Dilated_res_block(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp1 = pt_utils.Conv2d(d_in, d_out//2, kernel_size=(1,1), bn=True)\n",
    "        self.lfa = Building_block(d_out)\n",
    "        self.mlp2 = pt_utils.Conv2d(d_out, d_out*2, kernel_size=(1, 1), bn=True, activation=None)\n",
    "        self.shortcut = pt_utils.Conv2d(d_in, d_out*2, kernel_size=(1,1), bn=True, activation=None)\n",
    "\n",
    "    def forward(self, feature, xyz, neigh_idx):\n",
    "        f_pc = self.mlp1(feature)  # Batch*channel*npoints*1\n",
    "        f_pc = self.lfa(xyz, f_pc, neigh_idx)  # Batch*d_out*npoints*1\n",
    "        f_pc = self.mlp2(f_pc)\n",
    "        shortcut = self.shortcut(feature)\n",
    "        return F.leaky_relu(f_pc+shortcut, negative_slope=0.2)\n",
    "\n",
    "\n",
    "class Building_block(nn.Module):\n",
    "    def __init__(self, d_out):  #  d_in = d_out//2\n",
    "        super().__init__()\n",
    "        self.mlp1 = pt_utils.Conv2d(10, d_out//2, kernel_size=(1,1), bn=True)\n",
    "        self.att_pooling_1 = Att_pooling(d_out, d_out//2)\n",
    "\n",
    "        self.mlp2 = pt_utils.Conv2d(d_out//2, d_out//2, kernel_size=(1, 1), bn=True)\n",
    "        self.att_pooling_2 = Att_pooling(d_out, d_out)\n",
    "\n",
    "    def forward(self, xyz, feature, neigh_idx):  # feature: Batch*channel*npoints*1\n",
    "        f_xyz = self.relative_pos_encoding(xyz, neigh_idx)  # batch*npoint*nsamples*10\n",
    "        f_xyz = f_xyz.permute((0, 3, 1, 2)).contiguous()  # batch*10*npoint*nsamples\n",
    "        f_xyz = self.mlp1(f_xyz)\n",
    "        f_neighbours = self.gather_neighbour(\n",
    "            feature.squeeze(-1).permute((0, 2, 1)).contiguous(),neigh_idx\n",
    "        )  # batch*npoint*nsamples*channel\n",
    "        f_neighbours = f_neighbours.permute((0, 3, 1, 2)).contiguous()  # batch*channel*npoint*nsamples\n",
    "        f_concat = torch.cat([f_neighbours, f_xyz], dim=1)\n",
    "        f_pc_agg = self.att_pooling_1(f_concat)  # Batch*channel*npoints*1\n",
    "\n",
    "        f_xyz = self.mlp2(f_xyz)\n",
    "        f_neighbours = self.gather_neighbour(\n",
    "            f_pc_agg.squeeze(-1).permute((0, 2, 1)).contiguous(), neigh_idx\n",
    "        ).contiguous()  # batch*npoint*nsamples*channel\n",
    "        f_neighbours = f_neighbours.permute((0, 3, 1, 2)).contiguous()  # batch*channel*npoint*nsamples\n",
    "        f_concat = torch.cat([f_neighbours, f_xyz], dim=1)\n",
    "        f_pc_agg = self.att_pooling_2(f_concat)\n",
    "        return f_pc_agg\n",
    "\n",
    "    def relative_pos_encoding(self, xyz, neigh_idx):\n",
    "        neighbor_xyz = self.gather_neighbour(xyz, neigh_idx)  # batch*npoint*nsamples*3\n",
    "\n",
    "        xyz_tile = xyz.unsqueeze(2).repeat(1, 1, neigh_idx.shape[-1], 1)  # batch*npoint*nsamples*3\n",
    "        relative_xyz = xyz_tile - neighbor_xyz  # batch*npoint*nsamples*3\n",
    "        relative_dis = torch.sqrt(torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True))  # batch*npoint*nsamples*1\n",
    "        relative_feature = torch.cat([relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1)  # batch*npoint*nsamples*10\n",
    "        return relative_feature\n",
    "\n",
    "    @staticmethod\n",
    "    def gather_neighbour(pc, neighbor_idx):  # pc: batch*npoint*channel\n",
    "        # gather the coordinates or features of neighboring points\n",
    "        batch_size = pc.shape[0]\n",
    "        num_points = pc.shape[1]\n",
    "        d = pc.shape[2]\n",
    "        index_input = neighbor_idx.reshape(batch_size, -1)\n",
    "        features = torch.gather(pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2])).contiguous()\n",
    "        features = features.reshape(batch_size, num_points, neighbor_idx.shape[-1], d)  # batch*npoint*nsamples*channel\n",
    "        return features\n",
    "\n",
    "\n",
    "class Att_pooling(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Conv2d(d_in, d_in, (1, 1), bias=False)\n",
    "        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)\n",
    "\n",
    "    def forward(self, feature_set):\n",
    "\n",
    "        att_activation = self.fc(feature_set)\n",
    "        att_scores = F.softmax(att_activation, dim=3)\n",
    "        f_agg = feature_set * att_scores\n",
    "        f_agg = torch.sum(f_agg, dim=3, keepdim=True)\n",
    "        f_agg = self.mlp(f_agg)\n",
    "        return f_agg\n",
    "\n",
    "\n",
    "def compute_loss(end_points, cfg):\n",
    "\n",
    "    logits = end_points['logits']\n",
    "    labels = end_points['labels']\n",
    "\n",
    "    logits = logits.transpose(1, 2).reshape(-1, cfg.num_classes)\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    # Boolean mask of points that should be ignored\n",
    "    ignored_bool = labels == 0\n",
    "    for ign_label in cfg.ignored_label_inds:\n",
    "        ignored_bool = ignored_bool | (labels == ign_label)\n",
    "\n",
    "    # Collect logits and labels that are not ignored\n",
    "    valid_idx = ignored_bool == 0\n",
    "    valid_logits = logits[valid_idx, :]\n",
    "    valid_labels_init = labels[valid_idx]\n",
    "\n",
    "    # Reduce label values in the range of logit shape\n",
    "    reducing_list = torch.range(0, cfg.num_classes).long().cuda()\n",
    "    inserted_value = torch.zeros((1,)).long().cuda()\n",
    "    for ign_label in cfg.ignored_label_inds:\n",
    "        reducing_list = torch.cat([reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0)\n",
    "    valid_labels = torch.gather(reducing_list, 0, valid_labels_init)\n",
    "    loss = get_loss(valid_logits, valid_labels, cfg.class_weights)\n",
    "    end_points['valid_logits'], end_points['valid_labels'] = valid_logits, valid_labels\n",
    "    end_points['loss'] = loss\n",
    "    return loss, end_points\n",
    "\n",
    "\n",
    "def get_loss(logits, labels, pre_cal_weights):\n",
    "    # calculate the weighted cross entropy according to the inverse frequency\n",
    "    class_weights = torch.from_numpy(pre_cal_weights).float().cuda()\n",
    "    # one_hot_labels = F.one_hot(labels, self.config.num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction='none')\n",
    "    output_loss = criterion(logits, labels)\n",
    "    output_loss = output_loss.mean()\n",
    "    return output_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53764e",
   "metadata": {},
   "source": [
    "# FFB6D\n",
    "\n",
    "Finally add FFB6D and trace the model flow with TorchJitScript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c914164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.cnn.pspnet import PSPNet\n",
    "import models.pytorch_utils as pt_utils\n",
    "from models.RandLA.RandLANet import Network as RandLANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "psp_models = {\n",
    "    'resnet18': lambda: PSPNet(sizes=(1, 2, 3, 6), psp_size=512, deep_features_size=256, backend='resnet18'),\n",
    "    'resnet34': lambda: PSPNet(sizes=(1, 2, 3, 6), psp_size=512, deep_features_size=256, backend='resnet34'),\n",
    "    'resnet50': lambda: PSPNet(sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet50'),\n",
    "}\n",
    "\n",
    "\n",
    "class FFB6D(nn.Module):\n",
    "    def __init__(self, n_classes, n_pts, rndla_cfg, n_kps=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # ######################## prepare stages#########################\n",
    "        self.n_cls = n_classes\n",
    "        self.n_pts = n_pts\n",
    "        self.n_kps = n_kps\n",
    "        cnn = psp_models['resnet34'.lower()]()\n",
    "\n",
    "        rndla = RandLANet(rndla_cfg)\n",
    "\n",
    "        self.cnn_pre_stages = nn.Sequential (\n",
    "            cnn.feats.conv1,  # stride = 2, [bs, c, 240, 320]\n",
    "            cnn.feats.bn1, cnn.feats.relu,\n",
    "            cnn.feats.maxpool  # stride = 2, [bs, 64, 120, 160]\n",
    "        )\n",
    "        self.rndla_pre_stages = rndla.fc0\n",
    "\n",
    "        # ####################### downsample stages#######################\n",
    "        self.cnn_ds_stages = nn.ModuleList([\n",
    "            cnn.feats.layer1,    # stride = 1, [bs, 64, 120, 160]\n",
    "            cnn.feats.layer2,    # stride = 2, [bs, 128, 60, 80]\n",
    "            # stride = 1, [bs, 128, 60, 80]\n",
    "            nn.Sequential(cnn.feats.layer3, cnn.feats.layer4),\n",
    "            nn.Sequential(cnn.psp, cnn.drop_1)   # [bs, 1024, 60, 80]\n",
    "        ])\n",
    "        self.ds_sr = [4, 8, 8, 8]\n",
    "\n",
    "        self.rndla_ds_stages = rndla.dilated_res_blocks\n",
    "\n",
    "        self.ds_rgb_oc = [64, 128, 512, 1024]\n",
    "        self.ds_rndla_oc = [item * 2 for item in rndla_cfg.d_out]\n",
    "        self.ds_fuse_r2p_pre_layers = nn.ModuleList()\n",
    "        self.ds_fuse_r2p_fuse_layers = nn.ModuleList()\n",
    "        self.ds_fuse_p2r_pre_layers = nn.ModuleList()\n",
    "        self.ds_fuse_p2r_fuse_layers = nn.ModuleList()\n",
    "        for i in range(4):\n",
    "            self.ds_fuse_r2p_pre_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.ds_rgb_oc[i], self.ds_rndla_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "            self.ds_fuse_r2p_fuse_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.ds_rndla_oc[i]*2, self.ds_rndla_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.ds_fuse_p2r_pre_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.ds_rndla_oc[i], self.ds_rgb_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "            self.ds_fuse_p2r_fuse_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.ds_rgb_oc[i]*2, self.ds_rgb_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # ###################### upsample stages #############################\n",
    "        self.cnn_up_stages = nn.ModuleList([\n",
    "            nn.Sequential(cnn.up_1, cnn.drop_2),  # [bs, 256, 120, 160]\n",
    "            nn.Sequential(cnn.up_2, cnn.drop_2),  # [bs, 64, 240, 320]\n",
    "            nn.Sequential(cnn.final),  # [bs, 64, 240, 320]\n",
    "            nn.Sequential(cnn.up_3, cnn.final)  # [bs, 64, 480, 640]\n",
    "        ])\n",
    "        self.up_rgb_oc = [256, 64, 64]\n",
    "        self.up_rndla_oc = []\n",
    "        for j in range(rndla_cfg.num_layers):\n",
    "            if j < 3:\n",
    "                self.up_rndla_oc.append(self.ds_rndla_oc[-j-2])\n",
    "            else:\n",
    "                self.up_rndla_oc.append(self.ds_rndla_oc[0])\n",
    "\n",
    "        self.rndla_up_stages = rndla.decoder_blocks\n",
    "\n",
    "        n_fuse_layer = 3\n",
    "        self.up_fuse_r2p_pre_layers = nn.ModuleList()\n",
    "        self.up_fuse_r2p_fuse_layers = nn.ModuleList()\n",
    "        self.up_fuse_p2r_pre_layers = nn.ModuleList()\n",
    "        self.up_fuse_p2r_fuse_layers = nn.ModuleList()\n",
    "        for i in range(n_fuse_layer):\n",
    "            self.up_fuse_r2p_pre_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.up_rgb_oc[i], self.up_rndla_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "            self.up_fuse_r2p_fuse_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.up_rndla_oc[i]*2, self.up_rndla_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.up_fuse_p2r_pre_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.up_rndla_oc[i], self.up_rgb_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "            self.up_fuse_p2r_fuse_layers.append(\n",
    "                pt_utils.Conv2d(\n",
    "                    self.up_rgb_oc[i]*2, self.up_rgb_oc[i], kernel_size=(1, 1),\n",
    "                    bn=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # ####################### prediction headers #############################\n",
    "        # We use 3D keypoint prediction header for pose estimation following PVN3D\n",
    "        # You can use different prediction headers for different downstream tasks.\n",
    "\n",
    "        self.rgbd_seg_layer = (\n",
    "            pt_utils.Seq(self.up_rndla_oc[-1] + self.up_rgb_oc[-1])\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(n_classes, activation=None)\n",
    "        )\n",
    "\n",
    "        self.ctr_ofst_layer = (\n",
    "            pt_utils.Seq(self.up_rndla_oc[-1]+self.up_rgb_oc[-1])\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(3, activation=None)\n",
    "        )\n",
    "\n",
    "        self.kp_ofst_layer = (\n",
    "            pt_utils.Seq(self.up_rndla_oc[-1]+self.up_rgb_oc[-1])\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(128, bn=True, activation=nn.ReLU())\n",
    "            .conv1d(n_kps*3, activation=None)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def random_sample(feature, pool_idx):\n",
    "        \"\"\"\n",
    "        :param feature: [B, N, d] input features matrix\n",
    "        :param pool_idx: [B, N', max_num] N' < N, N' is the selected position after pooling\n",
    "        :return: pool_features = [B, N', d] pooled features matrix\n",
    "        \"\"\"\n",
    "        if len(feature.size()) > 3:\n",
    "            feature = feature.squeeze(dim=3)  # batch*channel*npoints\n",
    "        num_neigh = pool_idx.shape[-1]\n",
    "        d = feature.shape[1]\n",
    "        batch_size = pool_idx.shape[0]\n",
    "        pool_idx = pool_idx.reshape(batch_size, -1)  # batch*(npoints,nsamples)\n",
    "        pool_features = torch.gather(\n",
    "            feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)\n",
    "        ).contiguous()\n",
    "        pool_features = pool_features.reshape(batch_size, d, -1, num_neigh)\n",
    "        pool_features = pool_features.max(dim=3, keepdim=True)[0]  # batch*channel*npoints*1\n",
    "        return pool_features\n",
    "\n",
    "    @staticmethod\n",
    "    def nearest_interpolation(feature, interp_idx):\n",
    "        \"\"\"\n",
    "        :param feature: [B, N, d] input features matrix\n",
    "        :param interp_idx: [B, up_num_points, 1] nearest neighbour index\n",
    "        :return: [B, up_num_points, d] interpolated features matrix\n",
    "        \"\"\"\n",
    "        feature = feature.squeeze(dim=3)  # batch*channel*npoints\n",
    "        batch_size = interp_idx.shape[0]\n",
    "        up_num_points = interp_idx.shape[1]\n",
    "        interp_idx = interp_idx.reshape(batch_size, up_num_points)\n",
    "        interpolated_features = torch.gather(\n",
    "            feature, 2, interp_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)\n",
    "        ).contiguous()\n",
    "        interpolated_features = interpolated_features.unsqueeze(3)  # batch*channel*npoints*1\n",
    "        return interpolated_features\n",
    "\n",
    "    def _break_up_pc(self, pc):\n",
    "        xyz = pc[:, :3, :].transpose(1, 2).contiguous()\n",
    "        features = (\n",
    "            pc[:, 3:, :].contiguous() if pc.size(1) > 3 else None\n",
    "        )\n",
    "        return xyz, features\n",
    "\n",
    "    def forward(\n",
    "        self, inputs, end_points=None, scale=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        inputs: dict of :\n",
    "            rgb         : FloatTensor [bs, 3, h, w]\n",
    "            dpt_nrm     : FloatTensor [bs, 6, h, w], 3c xyz in meter + 3c normal map\n",
    "            cld_rgb_nrm : FloatTensor [bs, 9, npts]\n",
    "            choose      : LongTensor [bs, 1, npts]\n",
    "            xmap, ymap: [bs, h, w]\n",
    "            K:          [bs, 3, 3]\n",
    "        Returns:\n",
    "            end_points:\n",
    "        \"\"\"\n",
    "        # ###################### prepare stages #############################\n",
    "        if not end_points:\n",
    "            end_points = {}\n",
    "        # ResNet pre + layer1 + layer2\n",
    "        rgb_emb = self.cnn_pre_stages(inputs['rgb'])  # stride = 2, [bs, c, 240, 320]\n",
    "        # rndla pre\n",
    "        xyz, p_emb = self._break_up_pc(inputs['cld_rgb_nrm'])\n",
    "        p_emb = inputs['cld_rgb_nrm']\n",
    "        p_emb = self.rndla_pre_stages(p_emb)\n",
    "        p_emb = p_emb.unsqueeze(dim=3)  # Batch*channel*npoints*1\n",
    "\n",
    "        # ###################### encoding stages #############################\n",
    "        ds_emb = []\n",
    "        for i_ds in range(4):\n",
    "            # encode rgb downsampled feature\n",
    "            rgb_emb0 = self.cnn_ds_stages[i_ds](rgb_emb)\n",
    "            bs, c, hr, wr = rgb_emb0.size()\n",
    "\n",
    "            # encode point cloud downsampled feature\n",
    "            f_encoder_i = self.rndla_ds_stages[i_ds](\n",
    "                p_emb, inputs['cld_xyz%d' % i_ds], inputs['cld_nei_idx%d' % i_ds]\n",
    "            )\n",
    "            f_sampled_i = self.random_sample(f_encoder_i, inputs['cld_sub_idx%d' % i_ds])\n",
    "            p_emb0 = f_sampled_i\n",
    "            if i_ds == 0:\n",
    "                ds_emb.append(f_encoder_i)\n",
    "\n",
    "            # fuse point feauture to rgb feature\n",
    "            p2r_emb = self.ds_fuse_p2r_pre_layers[i_ds](p_emb0)\n",
    "            p2r_emb = self.nearest_interpolation(\n",
    "                p2r_emb, inputs['p2r_ds_nei_idx%d' % i_ds]\n",
    "            )\n",
    "            p2r_emb = p2r_emb.view(bs, -1, hr, wr)\n",
    "            rgb_emb = self.ds_fuse_p2r_fuse_layers[i_ds](\n",
    "                torch.cat((rgb_emb0, p2r_emb), dim=1)\n",
    "            )\n",
    "\n",
    "            # fuse rgb feature to point feature\n",
    "            r2p_emb = self.random_sample(\n",
    "                rgb_emb0.reshape(bs, c, hr*wr, 1), inputs['r2p_ds_nei_idx%d' % i_ds]\n",
    "            ).view(bs, c, -1, 1)\n",
    "            r2p_emb = self.ds_fuse_r2p_pre_layers[i_ds](r2p_emb)\n",
    "            p_emb = self.ds_fuse_r2p_fuse_layers[i_ds](\n",
    "                torch.cat((p_emb0, r2p_emb), dim=1)\n",
    "            )\n",
    "            ds_emb.append(p_emb)\n",
    "\n",
    "        # ###################### decoding stages #############################\n",
    "        n_up_layers = len(self.rndla_up_stages)\n",
    "        for i_up in range(n_up_layers-1):\n",
    "            # decode rgb upsampled feature\n",
    "            rgb_emb0 = self.cnn_up_stages[i_up](rgb_emb)\n",
    "            bs, c, hr, wr = rgb_emb0.size()\n",
    "\n",
    "            # decode point cloud upsampled feature\n",
    "            f_interp_i = self.nearest_interpolation(\n",
    "                p_emb, inputs['cld_interp_idx%d' % (n_up_layers-i_up-1)]\n",
    "            )\n",
    "            f_decoder_i = self.rndla_up_stages[i_up](\n",
    "                torch.cat([ds_emb[-i_up - 2], f_interp_i], dim=1)\n",
    "            )\n",
    "            p_emb0 = f_decoder_i\n",
    "\n",
    "            # fuse point feauture to rgb feature\n",
    "            p2r_emb = self.up_fuse_p2r_pre_layers[i_up](p_emb0)\n",
    "            p2r_emb = self.nearest_interpolation(\n",
    "                p2r_emb, inputs['p2r_up_nei_idx%d' % i_up]\n",
    "            )\n",
    "            p2r_emb = p2r_emb.view(bs, -1, hr, wr)\n",
    "            rgb_emb = self.up_fuse_p2r_fuse_layers[i_up](\n",
    "                torch.cat((rgb_emb0, p2r_emb), dim=1)\n",
    "            )\n",
    "\n",
    "            # fuse rgb feature to point feature\n",
    "            r2p_emb = self.random_sample(\n",
    "                rgb_emb0.reshape(bs, c, hr*wr), inputs['r2p_up_nei_idx%d' % i_up]\n",
    "            ).view(bs, c, -1, 1)\n",
    "            r2p_emb = self.up_fuse_r2p_pre_layers[i_up](r2p_emb)\n",
    "            p_emb = self.up_fuse_r2p_fuse_layers[i_up](\n",
    "                torch.cat((p_emb0, r2p_emb), dim=1)\n",
    "            )\n",
    "\n",
    "        # final upsample layers:\n",
    "        rgb_emb = self.cnn_up_stages[n_up_layers-1](rgb_emb)\n",
    "        f_interp_i = self.nearest_interpolation(\n",
    "            p_emb, inputs['cld_interp_idx%d' % (0)]\n",
    "        )\n",
    "        p_emb = self.rndla_up_stages[n_up_layers-1](\n",
    "            torch.cat([ds_emb[0], f_interp_i], dim=1)\n",
    "        ).squeeze(-1)\n",
    "\n",
    "        bs, di, _, _ = rgb_emb.size()\n",
    "        rgb_emb_c = rgb_emb.view(bs, di, -1)\n",
    "        choose_emb = inputs['choose'].repeat(1, di, 1)\n",
    "        rgb_emb_c = torch.gather(rgb_emb_c, 2, choose_emb).contiguous()\n",
    "\n",
    "        # Use DenseFusion in final layer, which will hurt performance due to overfitting\n",
    "        # rgbd_emb = self.fusion_layer(rgb_emb, pcld_emb)\n",
    "\n",
    "        # Use simple concatenation. Good enough for fully fused RGBD feature.\n",
    "        rgbd_emb = torch.cat([rgb_emb_c, p_emb], dim=1)\n",
    "\n",
    "        # ###################### prediction stages #############################\n",
    "        rgbd_segs = self.rgbd_seg_layer(rgbd_emb)\n",
    "        pred_kp_ofs = self.kp_ofst_layer(rgbd_emb)\n",
    "        pred_ctr_ofs = self.ctr_ofst_layer(rgbd_emb)\n",
    "\n",
    "        pred_kp_ofs = pred_kp_ofs.view(\n",
    "            bs, self.n_kps, 3, -1\n",
    "        ).permute(0, 1, 3, 2).contiguous()\n",
    "        pred_ctr_ofs = pred_ctr_ofs.view(\n",
    "            bs, 1, 3, -1\n",
    "        ).permute(0, 1, 3, 2).contiguous()\n",
    "\n",
    "        # return rgbd_seg, pred_kp_of, pred_ctr_of\n",
    "        end_points['pred_rgbd_segs'] = rgbd_segs\n",
    "        end_points['pred_kp_ofs'] = pred_kp_ofs\n",
    "        end_points['pred_ctr_ofs'] = pred_ctr_ofs\n",
    "\n",
    "        return end_points\n",
    "\n",
    "\n",
    "# Copy from PVN3D: https://github.com/ethnhe/PVN3D\n",
    "class DenseFusion(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super(DenseFusion, self).__init__()\n",
    "        self.conv2_rgb = torch.nn.Conv1d(64, 256, 1)\n",
    "        self.conv2_cld = torch.nn.Conv1d(32, 256, 1)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv1d(96, 512, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(512, 1024, 1)\n",
    "\n",
    "        self.ap1 = torch.nn.AvgPool1d(num_points)\n",
    "\n",
    "    def forward(self, rgb_emb, cld_emb):\n",
    "        bs, _, n_pts = cld_emb.size()\n",
    "        feat_1 = torch.cat((rgb_emb, cld_emb), dim=1)\n",
    "        rgb = F.relu(self.conv2_rgb(rgb_emb))\n",
    "        cld = F.relu(self.conv2_cld(cld_emb))\n",
    "\n",
    "        feat_2 = torch.cat((rgb, cld), dim=1)\n",
    "\n",
    "        rgbd = F.relu(self.conv3(feat_1))\n",
    "        rgbd = F.relu(self.conv4(rgbd))\n",
    "\n",
    "        ap_x = self.ap1(rgbd)\n",
    "\n",
    "        ap_x = ap_x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "        return torch.cat([feat_1, feat_2, ap_x], 1)  # 96+ 512 + 1024 = 1632\n",
    "\n",
    "\n",
    "def main():\n",
    "    from common import ConfigRandLA\n",
    "    rndla_cfg = ConfigRandLA\n",
    "\n",
    "    n_cls = 3\n",
    "    model = FFB6D(n_cls, rndla_cfg.num_points, rndla_cfg)\n",
    "    print(model)\n",
    "    #ffb6d_scripted =torch.jit.script(model)\n",
    "\n",
    "\n",
    "    print(\n",
    "        \"model parameters:\", sum(param.numel() for param in model.parameters())\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38d721",
   "metadata": {},
   "source": [
    "Provide input from example data to trace the flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0681c758",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'coremltools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5bf9ddba4efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'coremltools'"
     ]
    }
   ],
   "source": [
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ControlFlowNet(num_channels=3)\n",
    "scripted_model = torch.jit.script(model)\n",
    "\n",
    "mlmodel = coremltools.converters.convert(\n",
    "  scripted_model,\n",
    "  inputs=[coremltools.TensorType(shape=(1, 3, 64, 64))],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
